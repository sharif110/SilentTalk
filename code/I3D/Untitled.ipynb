{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faec4661",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets.nslt_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_i3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InceptionI3d\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# from datasets.nslt_dataset import NSLT as Dataset\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnslt_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NSLT \u001b[38;5;28;01mas\u001b[39;00m Dataset\n\u001b[0;32m     22\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_DEVICE_ORDER\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCI_BUS_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets.nslt_dataset'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "\n",
    "from torchvision import transforms\n",
    "import videotransforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from configs import Config\n",
    "from pytorch_i3d import InceptionI3d\n",
    "\n",
    "# from datasets.nslt_dataset import NSLT as Dataset\n",
    "from datasets.nslt_dataset import NSLT as Dataset\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-mode', type=str, help='rgb or flow')\n",
    "parser.add_argument('-save_model', type=str)\n",
    "parser.add_argument('-root', type=str)\n",
    "parser.add_argument('--num_class', type=int)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def run(configs,\n",
    "        mode='rgb',\n",
    "        root='/ssd/Charades_v1_rgb',\n",
    "        train_split='charades/charades.json',\n",
    "        save_model='',\n",
    "        weights=None):\n",
    "    print(configs)\n",
    "\n",
    "    # setup dataset\n",
    "    train_transforms = transforms.Compose([videotransforms.RandomCrop(224),\n",
    "                                           videotransforms.RandomHorizontalFlip(), ])\n",
    "    test_transforms = transforms.Compose([videotransforms.CenterCrop(224)])\n",
    "\n",
    "    dataset = Dataset(train_split, 'train', root, mode, train_transforms)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=configs.batch_size, shuffle=True, num_workers=0,\n",
    "                                             pin_memory=True)\n",
    "\n",
    "    val_dataset = Dataset(train_split, 'test', root, mode, test_transforms)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=configs.batch_size, shuffle=True, num_workers=2,\n",
    "                                                 pin_memory=False)\n",
    "\n",
    "    dataloaders = {'train': dataloader, 'test': val_dataloader}\n",
    "    datasets = {'train': dataset, 'test': val_dataset}\n",
    "\n",
    "    # setup the model\n",
    "    if mode == 'flow':\n",
    "        i3d = InceptionI3d(400, in_channels=2)\n",
    "        i3d.load_state_dict(torch.load('weights/flow_imagenet.pt'))\n",
    "    else:\n",
    "        i3d = InceptionI3d(400, in_channels=3)\n",
    "        i3d.load_state_dict(torch.load('weights/rgb_imagenet.pt'))\n",
    "\n",
    "    num_classes = dataset.num_classes\n",
    "    i3d.replace_logits(num_classes)\n",
    "\n",
    "    if weights:\n",
    "        print('loading weights {}'.format(weights))\n",
    "        i3d.load_state_dict(torch.load(weights))\n",
    "\n",
    "    i3d.cuda()\n",
    "    i3d = nn.DataParallel(i3d)\n",
    "\n",
    "    lr = configs.init_lr\n",
    "    weight_decay = configs.adam_weight_decay\n",
    "    optimizer = optim.Adam(i3d.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    num_steps_per_update = configs.update_per_step  # accum gradient\n",
    "    steps = 0\n",
    "    epoch = 0\n",
    "\n",
    "    best_val_score = 0\n",
    "    # train it\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.3)\n",
    "    while steps < configs.max_steps and epoch < 400:  # for epoch in range(num_epochs):\n",
    "        print('Step {}/{}'.format(steps, configs.max_steps))\n",
    "        print('-' * 10)\n",
    "\n",
    "        epoch += 1\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            collected_vids = []\n",
    "\n",
    "            if phase == 'train':\n",
    "                i3d.train(True)\n",
    "            else:\n",
    "                i3d.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            tot_loss = 0.0\n",
    "            tot_loc_loss = 0.0\n",
    "            tot_cls_loss = 0.0\n",
    "            num_iter = 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int)\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                num_iter += 1\n",
    "                # get the inputs\n",
    "                if data == -1: # bracewell does not compile opencv with ffmpeg, strange errors occur resulting in no video loaded\n",
    "                    continue\n",
    "\n",
    "                # inputs, labels, vid, src = data\n",
    "                inputs, labels, vid = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                inputs = inputs.cuda()\n",
    "                t = inputs.size(2)\n",
    "                labels = labels.cuda()\n",
    "\n",
    "                per_frame_logits = i3d(inputs, pretrained=False)\n",
    "                # upsample to input size\n",
    "                per_frame_logits = F.upsample(per_frame_logits, t, mode='linear')\n",
    "\n",
    "                # compute localization loss\n",
    "                loc_loss = F.binary_cross_entropy_with_logits(per_frame_logits, labels)\n",
    "                tot_loc_loss += loc_loss.data.item()\n",
    "\n",
    "                predictions = torch.max(per_frame_logits, dim=2)[0]\n",
    "                gt = torch.max(labels, dim=2)[0]\n",
    "\n",
    "                # compute classification loss (with max-pooling along time B x C x T)\n",
    "                cls_loss = F.binary_cross_entropy_with_logits(torch.max(per_frame_logits, dim=2)[0],\n",
    "                                                              torch.max(labels, dim=2)[0])\n",
    "                tot_cls_loss += cls_loss.data.item()\n",
    "\n",
    "                for i in range(per_frame_logits.shape[0]):\n",
    "                    confusion_matrix[torch.argmax(gt[i]).item(), torch.argmax(predictions[i]).item()] += 1\n",
    "\n",
    "                loss = (0.5 * loc_loss + 0.5 * cls_loss) / num_steps_per_update\n",
    "                tot_loss += loss.data.item()\n",
    "                if num_iter == num_steps_per_update // 2:\n",
    "                    print(epoch, steps, loss.data.item())\n",
    "                loss.backward()\n",
    "\n",
    "                if num_iter == num_steps_per_update and phase == 'train':\n",
    "                    steps += 1\n",
    "                    num_iter = 0\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    # lr_sched.step()\n",
    "                    if steps % 10 == 0:\n",
    "                        acc = float(np.trace(confusion_matrix)) / np.sum(confusion_matrix)\n",
    "                        print(\n",
    "                            'Epoch {} {} Loc Loss: {:.4f} Cls Loss: {:.4f} Tot Loss: {:.4f} Accu :{:.4f}'.format(epoch,\n",
    "                                                                                                                 phase,\n",
    "                                                                                                                 tot_loc_loss / (10 * num_steps_per_update),\n",
    "                                                                                                                 tot_cls_loss / (10 * num_steps_per_update),\n",
    "                                                                                                                 tot_loss / 10,\n",
    "                                                                                                                 acc))\n",
    "                        tot_loss = tot_loc_loss = tot_cls_loss = 0.\n",
    "            if phase == 'test':\n",
    "                val_score = float(np.trace(confusion_matrix)) / np.sum(confusion_matrix)\n",
    "                if val_score > best_val_score or epoch % 2 == 0:\n",
    "                    best_val_score = val_score\n",
    "                    model_name = save_model + \"nslt_\" + str(num_classes) + \"_\" + str(steps).zfill(\n",
    "                                   6) + '_%3f.pt' % val_score\n",
    "\n",
    "                    torch.save(i3d.module.state_dict(), model_name)\n",
    "                    print(model_name)\n",
    "\n",
    "                print('VALIDATION: {} Loc Loss: {:.4f} Cls Loss: {:.4f} Tot Loss: {:.4f} Accu :{:.4f}'.format(phase,\n",
    "                                                                                                              tot_loc_loss / num_iter,\n",
    "                                                                                                              tot_cls_loss / num_iter,\n",
    "                                                                                                              (tot_loss * num_steps_per_update) / num_iter,\n",
    "                                                                                                              val_score\n",
    "                                                                                                              ))\n",
    "\n",
    "                scheduler.step(tot_loss * num_steps_per_update / num_iter)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # WLASL setting\n",
    "    mode = 'rgb'\n",
    "    root = {'word': '../../data/WLASL2000'}\n",
    "\n",
    "    save_model = 'checkpoints/'\n",
    "    train_split = 'preprocess/nslt_2000.json'\n",
    "\n",
    "    # weights = 'archived/asl2000/FINAL_nslt_2000_iters=5104_top1=32.48_top5=57.31_top10=66.31.pt'\n",
    "    weights = None\n",
    "    config_file = 'configfiles/asl2000.ini'\n",
    "\n",
    "    configs = Config(config_file)\n",
    "    print(root, train_split)\n",
    "    run(configs=configs, mode=mode, root=root, save_model=save_model, train_split=train_split, weights=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10dc6c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/20/ac/ab6f42af83349e679b03c9bb18354740c6b58b17dba329fb408730230584/torchvision-0.16.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchvision-0.16.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torchvision) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pc\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jinja2->torch==2.1.0->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.16.0-cp311-cp311-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.3 MB 1.4 MB/s eta 0:00:01\n",
      "    --------------------------------------- 0.0/1.3 MB 1.4 MB/s eta 0:00:01\n",
      "   - -------------------------------------- 0.1/1.3 MB 409.6 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.3 MB 476.3 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.3 MB 476.3 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.1/1.3 MB 425.1 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.2/1.3 MB 689.2 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.2/1.3 MB 656.0 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.3 MB 781.9 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.5/1.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.6/1.3 MB 1.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.7/1.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.0/1.3 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.0/1.3 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3942c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement datasets.nslt_dataset (from versions: none)\n",
      "ERROR: No matching distribution found for datasets.nslt_dataset\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets.nslt_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f595347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
